{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50e0b0-737a-44cc-90d2-2397947682a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import torch # needed for replay feature\n",
    "import torchvision.models as torchvision_models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "from TraceLens import TreePerfAnalyzer, EventReplayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ea3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a dir and cwd to it\n",
    "def create_dir_and_cwd(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    os.chdir(dir_name)\n",
    "    print(f\"Changed working directory to: {os.getcwd()}\")\n",
    "\n",
    "create_dir_and_cwd(\"event_replay_example_wd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f992e69-17bf-43fc-9508-fa6c83f7020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will profile a resnet model to demo event replay\n",
    "# If you want to replay from TraceLens perf report, you can skip down the notebook\n",
    "\n",
    "def profile_resnet(path=None):\n",
    "    device = \"cuda\"\n",
    "    dtype = torch.bfloat16\n",
    "    model = torchvision_models.resnet18().to(device=device, dtype=dtype)\n",
    "    batch = 20\n",
    "    C_IN, H_IN, W_IN = 3, 224, 224\n",
    "    dummy_input = torch.randn(batch, C_IN, H_IN, W_IN).to(device=device, dtype=dtype)\n",
    "    dummy_output = torch.randn(batch, 1000).to(device=device, dtype=dtype)\n",
    "    if path is None:\n",
    "        path = \"resnet_trace.json\"\n",
    "    def trace_handler(p):\n",
    "        p.export_chrome_trace(path)\n",
    "    activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n",
    "    with profile(\n",
    "        activities=activities,\n",
    "        schedule=torch.profiler.schedule(\n",
    "            wait=10,\n",
    "            warmup=5,\n",
    "            active=3,\n",
    "            repeat=1\n",
    "            ),\n",
    "        record_shapes=True,\n",
    "        on_trace_ready=trace_handler\n",
    "    ) as p:\n",
    "        for idx in range(50):\n",
    "            out = model(dummy_input)\n",
    "            out.backward(dummy_output)\n",
    "            p.step()\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4759c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_path = profile_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91964c2-2e9c-48a2-80be-5adf769c46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace by your profile path, it can be a single rank profile from a multi gpu run as well\n",
    "# If you are interested in replaying from perf report then skip down \n",
    "perf_analyzer = TreePerfAnalyzer.from_file(profile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af214e4-31fa-4934-8b6c-5487eae030ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kernel_launchers = perf_analyzer.get_df_kernel_launchers(include_kernel_names=True)\n",
    "\n",
    "# lets take conv bwd op as example\n",
    "df_kernel_launchers_unique_args = perf_analyzer.get_df_kernel_launchers_unique_args(df_kernel_launchers, include_pct=True)\n",
    "df_kernel_launchers_unique_args.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6dd585-a916-4795-8aee-84dbcc2f78dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get interesting op to replay based on row idx or any other method you like\n",
    "device=\"cuda\"\n",
    "row_idx = 11\n",
    "row = df_kernel_launchers_unique_args.iloc[row_idx]\n",
    "uid = row['ex_UID'] # get uid for row of interest\n",
    "evt_to_replay = perf_analyzer.tree.get_UID2event(uid)\n",
    "my_replayer = EventReplayer(evt_to_replay, device=device, verbose=True)\n",
    "my_replayer.replay()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337c7e3-3f7c-4809-b1fc-030bdf80fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very useful for understanding the op args\n",
    "\n",
    "my_replayer.get_repro_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2328dd7-7333-4d85-9304-e5a784c442f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a very quick and dirty benchmark function to check the fidelity of the replayed op\n",
    "def benchmark_func(func, device, warmup=50, avg_steps=100):\n",
    "    \"\"\"\n",
    "    Benchmark a function with warmup and average steps.\n",
    "    Disclaimer: This method would be inaccurate for very short ops.\n",
    "    Args:\n",
    "        func (callable): The function to benchmark.\n",
    "        warmup (int): Number of warmup iterations.\n",
    "        avg_steps (int): Number of iterations to average over.\n",
    "    Returns:\n",
    "        float: Average time taken per iteration in microseconds.\n",
    "    \"\"\"\n",
    "    # Warmup phase\n",
    "    for _ in range(warmup):\n",
    "        func()\n",
    "\n",
    "    # Benchmarking phase\n",
    "    torch.cuda.synchronize(device)\n",
    "    start_time = time.time()\n",
    "    for _ in range(avg_steps):\n",
    "        func()\n",
    "    torch.cuda.synchronize(device)\n",
    "    end_time = time.time()\n",
    "\n",
    "    elapsed_time = end_time - start_time\n",
    "    avg_time_sec = elapsed_time / avg_steps\n",
    "    avg_time_us = avg_time_sec * 1e6\n",
    "\n",
    "    return avg_time_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d568b-af75-4ea7-ae01-edb675e8da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check fidelity of replay\n",
    "replay_time_mean = benchmark_func(my_replayer.replay, device)\n",
    "profile_time_mean = row['total_direct_kernel_time_mean']\n",
    "percent_diff = (replay_time_mean - profile_time_mean) / profile_time_mean * 100\n",
    "print(f\"Average time per replay: {replay_time_mean:.2f} us\")\n",
    "print(f\"Profile time mean: {profile_time_mean:.2f} us\")\n",
    "print(f\"Percent difference: {percent_diff:.2f}%\")\n",
    "print(f\"Abs difference: {replay_time_mean - profile_time_mean:.2f} us\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets further verify the replay fidelity by profiling the replay\n",
    "# and checking the kernels \n",
    "def profile_the_replay(replayer, path=\"replay_trace.json\"):\n",
    "    \"\"\"\n",
    "    Profile the replay of an event.\n",
    "    I know the name is confusing, \n",
    "    but what I mean is that we are profiling the replay of the event\n",
    "    Args:\n",
    "        replayer (EventReplayer): The EventReplayer object.\n",
    "        warmup (int): Number of warmup iterations.\n",
    "        avg_steps (int): Number of iterations to average over.\n",
    "    Returns:\n",
    "        str: path of the replayed events trace\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def trace_handler(p):\n",
    "        p.export_chrome_trace(path)\n",
    "    activities = [ProfilerActivity.CPU, ProfilerActivity.CUDA]\n",
    "    wait = 10\n",
    "    warmup = 5\n",
    "    active = 10\n",
    "    with profile(\n",
    "        activities=activities,\n",
    "        schedule=torch.profiler.schedule(\n",
    "            wait=wait,\n",
    "            warmup=warmup,\n",
    "            active=active,\n",
    "            repeat=1\n",
    "            ),\n",
    "        record_shapes=True,\n",
    "        on_trace_ready=trace_handler\n",
    "    ) as p:\n",
    "        for idx in range(wait + warmup + active):\n",
    "            replayer.replay()\n",
    "            p.step()\n",
    "\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_profile_path = profile_the_replay(my_replayer)\n",
    "replay_perf_analyzer = TreePerfAnalyzer.from_file(replay_profile_path)\n",
    "replay_evts = [e for e in replay_perf_analyzer.tree.events if e.get('name') == my_replayer.event.get('name')]\n",
    "replay_evt = replay_evts[0]\n",
    "replay_kernels = [replay_perf_analyzer.tree.get_UID2event(uid) for uid in replay_evt.get('gpu_events', [])]\n",
    "replay_kernels_names = [e.get('name') for e in replay_kernels]\n",
    "gt_kernels = [perf_analyzer.tree.get_UID2event(uid) for uid in evt_to_replay.get('gpu_events', [])]\n",
    "gt_kernels_names = [e.get('name') for e in gt_kernels]\n",
    "print(f\"GT kernels:\")\n",
    "for gt_name in gt_kernels_names:\n",
    "    print(gt_name[:128])\n",
    "print()\n",
    "print(\"Replay kernels:\")\n",
    "for replay_name in replay_kernels_names:\n",
    "    print(replay_name[:128])\n",
    "print()\n",
    "assert set(replay_kernels_names) == set(gt_kernels_names), f\"Replay kernels: {set(replay_kernels_names)} do not match ground truth kernels: {set(gt_kernels_names)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1d5df",
   "metadata": {},
   "source": [
    "Replaying a bunch of operations -  batched replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda5a18-2783-40ed-a793-4f5192d265d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of events of interest for batched replay and repro generation\n",
    "# lets say we are interested in all conv bwd ops\n",
    "ops_interest = []\n",
    "df_kernel_launchers_filt = df_kernel_launchers_unique_args[df_kernel_launchers_unique_args['name']=='aten::convolution_backward']\n",
    "for index, row in df_kernel_launchers_filt.iterrows():\n",
    "    uid = row['ex_UID']  # get uid for row of interest\n",
    "    event = perf_analyzer.tree.get_UID2event(uid)\n",
    "    ops_interest.append(event)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d7608f-30d2-4aae-9361-6feb111b878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save replay info as json\n",
    "import json\n",
    "repro_data_list = []\n",
    "processed_count = 0\n",
    "\n",
    "for event in ops_interest:\n",
    "    # Initialize EventReplayer (device doesn't matter here, just for schema matching)\n",
    "    # Set lazy=True as we only need the IR, not immediate tensor creation.\n",
    "    # Verbose can be helpful for debugging schema mismatches during extraction.\n",
    "    replayer = EventReplayer(event, lazy=True, verbose=False) # Set verbose=True for debug\n",
    "\n",
    "    # Extract the serializable info\n",
    "    repro_info = replayer.get_repro_info()\n",
    "    repro_data_list.append(repro_info)\n",
    "    processed_count += 1\n",
    "\n",
    "\n",
    "# --- Save the Extracted Data ---\n",
    "OUTPUT_REPRO_FILE = 'event_replay_ir.json'\n",
    "if repro_data_list:\n",
    "    print(f\"\\nSaving {len(repro_data_list)} extracted operator infos to '{OUTPUT_REPRO_FILE}'...\")\n",
    "    with open(OUTPUT_REPRO_FILE, 'w') as f:\n",
    "        json.dump(repro_data_list, f, indent=4)\n",
    "    print(\"Save complete.\")\n",
    "\n",
    "abs_path_replay_ir_json = os.path.abspath(OUTPUT_REPRO_FILE)\n",
    "print(f\"Repro data saved to: {abs_path_replay_ir_json}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f742df8-8c59-40f3-976b-95cbabd2fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the batched replay\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "from TraceLens import EventReplay\n",
    "dir_batched_replay = os.path.dirname(EventReplay.__file__)\n",
    "batched_replay_file = os.path.join(dir_batched_replay, \"batched_replay.py\")\n",
    "print(f\"Running batched replay from directory: {dir_batched_replay}\")\n",
    "cmd = [\n",
    "    \"python\",          # run as \"python ...\"\n",
    "    batched_replay_file, # path to the batched replay script\n",
    "    abs_path_replay_ir_json, # path to the replay IR file\n",
    "    \"--verbose\"\n",
    "]\n",
    "result = subprocess.run(cmd, cwd=dir_batched_replay,\n",
    "                        capture_output=True, text=True)\n",
    "if result.returncode != 0:\n",
    "    print(f\"Error running batched replay: {result.stderr}\")\n",
    "else:\n",
    "    print(\"Batched replay completed successfully.\")\n",
    "    print(result.stdout)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7faeb-bbc0-4b90-bde2-7f468c4477a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDALONE ARTIFACTS FOR REPRO -  independent of model code or tracelens code\n",
    "# artifacts include (a)replay_ir.json, (b) utils.py, (c) batched_replay.py\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "utils_file_path = os.path.join(dir_batched_replay, \"utils.py\")\n",
    "batched_replay_file = os.path.join(dir_batched_replay, \"batched_replay.py\")\n",
    "readme_file_path = os.path.join(dir_batched_replay, \"batched_replay_readme.md\")\n",
    "files = [\n",
    "    abs_path_replay_ir_json,  # Path to the replay IR file\n",
    "    utils_file_path,  # Path to utils.py\n",
    "    batched_replay_file,  # Path to batched_replay.py\n",
    "    readme_file_path  # path to the readme\n",
    "]\n",
    "zip_file_path = 'replay_code.zip'\n",
    "with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
    "    for file in files:\n",
    "        zipf.write(file, arcname=os.path.basename(file))  # ← use file.name\n",
    "print(f\"Created zip file: {zip_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1722250f",
   "metadata": {},
   "source": [
    "Replay ops from report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first generate the TraceLens perf report\n",
    "\n",
    "# hacky method to get the path to the TraceLens examples script\n",
    "import TraceLens\n",
    "TraceLens_dir = os.path.dirname(os.path.dirname(TraceLens.__file__))\n",
    "script_path = os.path.join(TraceLens_dir, 'examples', 'generate_perf_report.py')\n",
    "perf_report_path = \"perf_report.xlsx\"\n",
    "cmd = [\n",
    "    \"python\",          # run as \"python ...\"\n",
    "    script_path,      # path to the generate_perf_report.py script\n",
    "    \"--profile_json_path\", profile_path,  # path to the profile json file\n",
    "    \"--output_xlsx_path\", perf_report_path\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "if result.returncode != 0:\n",
    "    print(f\"Error generating perf report: {result.stderr}\")\n",
    "else:\n",
    "    print(\"Perf report generated successfully.\")\n",
    "    print(f\"Perf report saved to: {perf_report_path}\")\n",
    "    print(result.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ce15b-5f0a-4f8e-b7a2-f287154a5d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can replay events from the perf reports as well - without the full profile too!\n",
    "# This is because we essentially require the args and the op name to replay\n",
    "# excel -> df -> for each row (row -> event -> replayer -> replayer IR -> append to replayer IR list) -> save replayer IR list as json\n",
    "import pandas as pd\n",
    "import ast\n",
    "# read sheet from excel\n",
    "\n",
    "df_unique_ops = pd.read_excel('perf_report.xlsx', sheet_name='kernel_launchers_unique_args')\n",
    "\n",
    "def row_to_evt(row):\n",
    "    event = {\n",
    "        'name': row['name'],\n",
    "        'args': {\n",
    "            'Input Dims': ast.literal_eval(row['Input Dims']),\n",
    "            'Input Strides': ast.literal_eval(row['Input Strides']),\n",
    "            'Input type': ast.literal_eval(row['Input type']),\n",
    "            'Concrete Inputs': ast.literal_eval(row['Concrete Inputs']),\n",
    "        }\n",
    "    }\n",
    "    return event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "repro_data_list = []\n",
    "processed_count = 0\n",
    "# lets say we are interested in the following ops\n",
    "ops_interest = ['aten::miopen_convolution',\n",
    "                'aten::convolution_backward', \n",
    "                'aten::miopen_batch_norm',\n",
    "                'aten::miopen_batch_norm_backward'] \n",
    "\n",
    "df_ops_interest = df_unique_ops[df_unique_ops['name'].isin(ops_interest)].copy()\n",
    "\n",
    "for index, row in df_ops_interest.iterrows():\n",
    "    event = row_to_evt(row)\n",
    "    # Initialize EventReplayer similar to above\n",
    "    replayer = EventReplayer(event, lazy=True, verbose=False)\n",
    "    # Extract the serializable info\n",
    "    repro_info = replayer.get_repro_info()\n",
    "    repro_data_list.append(repro_info)\n",
    "    processed_count += 1\n",
    "print(f\"Processed {processed_count} events.\")\n",
    "# --- Save the Extracted Data ---\n",
    "OUTPUT_REPRO_FILE = 'report_event_replay_ir.json'\n",
    "if repro_data_list:\n",
    "    print(f\"\\nSaving {len(repro_data_list)} extracted operator infos to '{OUTPUT_REPRO_FILE}'...\")\n",
    "    with open(OUTPUT_REPRO_FILE, 'w') as f:\n",
    "        json.dump(repro_data_list, f, indent=4)\n",
    "    print(\"Save complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0245187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDALONE ARTIFACTS FOR REPRO -  independent of model code or tracelens code - same drill as before\n",
    "# artifacts include (a)replay_ir.json, (b) utils.py, (c) batched_replay.py\n",
    "files = [\n",
    "    OUTPUT_REPRO_FILE,  # Path to the replay IR file\n",
    "    utils_file_path,  # Path to utils.py\n",
    "    batched_replay_file,  # Path to batched_replay.py\n",
    "    readme_file_path  # path to the readme\n",
    "]\n",
    "zip_file_path = 'report_replay_code.zip'\n",
    "with zipfile.ZipFile(zip_file_path, 'w') as zipf:\n",
    "    for file in files:\n",
    "        zipf.write(file, arcname=os.path.basename(file))  # ← use file.name\n",
    "print(f\"Created zip file: {zip_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
